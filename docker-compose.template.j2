services:
  # FastAPI service
  app:
    build:
      context: .
      dockerfile: Dockerfile.cpu.final
      args:
        USER_UID: ${USER_UID}
        USER_GID: ${USER_GID}
    labels:
      autoheal-label: true
    {% if USE_MILVUS_LITE == "true" %}
    command: /bin/sh -c "uvicorn app.main:app --host 0.0.0.0 --port 80"
    {% else %}
    command: /bin/sh -c "python scripts/milvus_credentials_setup.py && uvicorn app.main:app --host 0.0.0.0 --port 80"
    {% endif %}
    env_file:
      - .env.final
    ports:
      - "${APP_HOST_PORT:-8000}:80"
    depends_on:
      celery_search_worker:
        condition: service_healthy
        restart: false
      celery_beat:
        condition: service_healthy
        restart: false
    {% if USE_MILVUS_LITE == "true" %}
    volumes:
      - ${DATA_DIRPATH}/volumes:/data
    {% endif %}
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:80/health"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 120s
    restart: always

  # Celery workers
  celery_search_worker:
    build:
      context: .
      dockerfile: Dockerfile.cpu.final
      args:
        USER_UID: ${USER_UID}
        USER_GID: ${USER_GID}
    command: >
      /bin/sh -c "celery -A app.celery_app worker --loglevel=info -Q search -c 8 -P threads -n search_worker@%h --prefetch-multiplier=4"
    labels:
      autoheal-label: true
    env_file:
      - .env.final
    depends_on:
      {% if USE_MILVUS_LITE == "false" %}
      milvus-standalone:
        condition: service_healthy
        restart: false
      {% endif %}
      mongo:
        condition: service_healthy
        restart: false
      {% if USE_LLM == "true" %}
      ollama:
        condition: service_healthy
        restart: false
      {% endif %}
      rabbitmq:
        condition: service_healthy
        restart: false
      redis:
        condition: service_healthy
        restart: false
    volumes:
      - ${DATA_DIRPATH}/model:/model
      {% if USE_MILVUS_LITE == "true" %}
      - ${DATA_DIRPATH}/volumes:/data
      {% endif %}
    healthcheck:
      test: ["CMD", "celery", "-A", "app.celery_app", "inspect", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  celery_maintenance_worker:
    build:
      context: .
      {% if USE_GPU == "true" %}
      dockerfile: Dockerfile.gpu.final
      {% else %}
      dockerfile: Dockerfile.cpu.final
      {% endif %}
      args:
        USER_UID: ${USER_UID}
        USER_GID: ${USER_GID}
    command: >
      /bin/sh -c "celery -A app.celery_app worker --loglevel=info -Q maintenance -c 8 -P prefork -n maintenance_worker@%h --prefetch-multiplier=1"
    labels:
      autoheal-label: true
    env_file:
      - .env.final
    depends_on:
      {% if USE_MILVUS_LITE == "false" %}
      milvus-standalone:
        condition: service_healthy
        restart: false
      {% endif %}
      mongo:
        condition: service_healthy
        restart: false
      {% if USE_LLM == "true" %}
      ollama:
        condition: service_healthy
        restart: false
      {% endif %}
      rabbitmq:
        condition: service_healthy
        restart: false
      redis:
        condition: service_healthy
        restart: false
    volumes:
      - ${DATA_DIRPATH}/model:/model
      - ${DATA_DIRPATH}/cold_data:/cold_data
      {% if USE_MILVUS_LITE == "true" %}
      - ${DATA_DIRPATH}/volumes:/data
      {% endif %}
    healthcheck:
      # TODO GPU specific healthcheck shouldn't be necessary once we resolve issue:
      # https://github.com/aiondemand/aiod-enhanced-interaction/issues/76
      {% if USE_GPU == "true" %}
      test: ["CMD-SHELL", "celery -A app.celery_app inspect ping && nvidia-smi || exit 1"]
      {% else %}
      test: ["CMD-SHELL", "celery -A app.celery_app inspect ping"]
      {% endif %}
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    {% if USE_GPU == "true" %}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    {% endif %}

  celery_beat:
    build:
      context: .
      dockerfile: Dockerfile.cpu.final
      args:
        USER_UID: ${USER_UID}
        USER_GID: ${USER_GID}
    command: >
      /bin/sh -c "celery -A app.celery_app beat --loglevel=info"
    labels:
      autoheal-label: true
    env_file:
      - .env.final
    depends_on:
      celery_maintenance_worker:
        condition: service_healthy
        restart: false
    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep '[c]elery.*beat' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
  {% if USE_LLM == "true" %}

  # Ollama service
  ollama:
    image: ollama/ollama:0.11.0
    labels:
      autoheal-label: true
    restart: always
    healthcheck:
      # TODO Same as above
      {% if USE_GPU == "true" %}
      test: ["CMD-SHELL", "ollama && nvidia-smi || exit 1"]
      {% else %}
      test: ["CMD", "ollama"]
      {% endif %}
      interval: 30s
      timeout: 20s
      retries: 3
    volumes:
      - ${DATA_DIRPATH}/ollama:/root/.ollama/
    ports:
      - "${OLLAMA_HOST_PORT:-11434}:11434"
    {% if USE_GPU == "true" %}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    {% endif %}
  {% endif %}
