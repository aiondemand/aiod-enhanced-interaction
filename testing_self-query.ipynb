{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO modifications\n",
    "\n",
    "Steps:\n",
    "- Build StructuredQuery (with limited comparators => EQ, GT, GTE, LT, LTE)\n",
    "- Translate to Milvus Query\n",
    "- Postprocessing:\n",
    "    - Check validity of values assigned to individual fields\n",
    "    - Regex: Replace EQ => ARRAY_CONTAINS for array metadata fields\n",
    "\n",
    "Problems with the current approach:\n",
    "- Doesnt adhere to schema or specified valid values (for enums and such)\n",
    "- Hallucination\n",
    "\n",
    "Potential solution: 2-stage user query building approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompt_values import HumanMessage\n",
    "\n",
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.chains.query_constructor.base import (\n",
    "    StructuredQueryOutputParser,\n",
    "    get_query_constructor_prompt\n",
    ")\n",
    "from langchain_core.structured_query import Comparator, Operator\n",
    "from langchain.retrievers.self_query.milvus import MilvusTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "MODEL_NAME = \"llama3.1:8b\"\n",
    "\n",
    "model = ChatOllama(model=MODEL_NAME, num_predict=4096, num_ctx=8192,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# model = AzureChatOpenAI(\n",
    "#     azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_metadata_filter import DatasetMetadataTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_types = {\n",
    "    \"platform\": \"string\",\n",
    "    \"date_published\": \"string\",\n",
    "    \"year\": \"integer\",\n",
    "    \"month\": \"integer\",\n",
    "    \"domains\": \"string\",\n",
    "    \"task_types\": \"string\",\n",
    "    \"license\": \"string\",\n",
    "    \"size_in_mb\": \"float\",\n",
    "    \"num_datapoints\": \"integer\",\n",
    "    \"size_category\": \"string\",\n",
    "    \"modalities\": \"string\",\n",
    "    \"data_formats\": \"string\",\n",
    "    \"languages\": \"string\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=name, \n",
    "        description=field.description, \n",
    "        type=attribute_types[name]\n",
    "    )\n",
    "    for name, field in DatasetMetadataTemplate.model_fields.items()\n",
    "]\n",
    "document_content_description = DatasetMetadataTemplate.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_comparators = [\n",
    "    Comparator.EQ,\n",
    "    Comparator.GT,\n",
    "    Comparator.GTE,\n",
    "    Comparator.LT,\n",
    "    Comparator.LTE\n",
    "]\n",
    "allowed_operators = [\n",
    "    Operator.AND, \n",
    "    Operator.OR, \n",
    "    Operator.NOT, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    (\n",
    "        \"Retrieve HuggingFace datasets about stocks\",\n",
    "        {\n",
    "            \"filter\": 'eq(\"platform\", \"huggingface\")',\n",
    "            \"query\": \"stock datasets\"\n",
    "        }\n",
    "    ),\n",
    "    (\n",
    "        \"Show me the summarization news datasets containing both the French as well as English data. The dataset however can't include any German data nor any Slovak data.\",\n",
    "        {\n",
    "            \"filter\": 'and(eq(\"task_types\", \"summarization\"), and(eq(\"languages\", \"fr\"), eq(\"languages\", \"en\")), not( or(eq(\"languages\", \"de\"), eq(\"languages\", \"sk\"))))',\n",
    "            \"query\": \"news datasets\"\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"Find all chocolate datasets created after January 1, 2022, that are represented in textual or image format with its dataset size smaller than 500 000KB.\",\n",
    "        {\n",
    "            \"filter\": 'and(gte(\"date_published\", \"2022-01-01\"), or(eq(\"modalities\", \"text\"), eq(\"modalities\", \"image\")), lt(\"size_in_mb\", 488))',\n",
    "            \"query\": \"chocolate datasets\"\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"COVID-19 datasets\",\n",
    "        {\n",
    "            \"filter\": \"NO_FILTER\",\n",
    "            \"query\": \"COVID-19 datasets\"\n",
    "        }\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_schema = \"\"\"\n",
    "<< Structured Request Schema >>\n",
    "\n",
    "When responding use a markdown code snippet with a JSON object formatted in the following schema:\n",
    "\n",
    "```json\n",
    "{{{{\n",
    "    \"filter\": string, \\\\ logical condition statement for filtering documents\n",
    "    \"query\": string \\\\ text string to compare to document contents\n",
    "}}}}\n",
    "```\n",
    "Your response should only consist of the said schema with no prefix or suffix. Respond only to the last user query as the others are only examples.\n",
    "\n",
    "The query string should contain only text that is expected to match the contents of documents or its main description. Any conditions in the filter should not be mentioned in the query as well.\n",
    "\n",
    "A logical condition statement is composed of one or more comparison and logical operation statements.\n",
    "\n",
    "A comparison statement takes the form: `comp(attr, val)`:\n",
    "- `comp` ({allowed_comparators}): comparator\n",
    "- `attr` (string):  name of attribute to apply the comparison to\n",
    "- `val` (string): is the comparison value\n",
    "\n",
    "A logical operation statement takes the form `op(statement1, statement2, ...)`:\n",
    "- `op` ({allowed_operators}): logical operator\n",
    "- `statement1`, `statement2`, ... (comparison statements or logical operation statements): one or more statements to apply the operation to\n",
    "\n",
    "Make sure that you only use the comparators and logical operators listed above and no others.\n",
    "Make sure that filters only refer to attributes that exist in the data source.\n",
    "Make sure that values of the filters equal to one of the values found within the 'valid_values' field representing the only permitted values of specific attributes.\n",
    "Make sure to include only those filters that are explicitly defined in the user query. Don't try to infer new ones based on the context.\n",
    "Make sure that filters take into account the descriptions of attributes and only make comparisons that are feasible given the type of data being stored. To this end, you may need to convert the filters to comply with expected values or formats.\n",
    "Make sure that filters are only used as needed. If there are no filters that should be applied return \"NO_FILTER\" for the filter value.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = get_query_constructor_prompt(\n",
    "    document_contents=\"Gist of the dataset\",\n",
    "    attribute_info=metadata_field_info,\n",
    "    allowed_comparators=allowed_comparators,\n",
    "    allowed_operators=allowed_operators,\n",
    "    examples=examples,\n",
    "    schema_prompt=custom_schema\n",
    ")\n",
    "output_parser = StructuredQueryOutputParser.from_components(fix_invalid=True)\n",
    "query_constructor = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = (\n",
    "    \"Retrieve all the translation Stanford datasets with at least 10k datapoints and has over 100k KB in size\" +\n",
    "    \"and the dataset should have contain Slovak language, Polish language, but no Czech language.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = (\n",
    "    \"Retrieve all translation datasets that either have at least 10k datapoints and has over 100k KB in size\" +\n",
    "    \"or they contain Slovak language and Polish language, but no Czech language.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Retrieve all the translation datasets from AIOD platform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"filter\": \"and(eq(\\\"task_types\\\", \\\"translation\\\"), eq(\\\"domains\\\", \\\"Stanford\\\"), gte(\\\"num_datapoints\\\", 10e4), gt(\\\"size_in_mb\\\", 100), and(eq(\\\"languages\\\", \\\"sk\\\"), eq(\\\"languages\\\", \\\"pl\\\")), not(eq(\\\"languages\\\", \\\"cz\\\")))\",\n",
      "    \"query\": \"translation datasets\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "output = query_constructor.invoke({\"query\": user_query})\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredQuery(query='translation datasets', filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='task_types', value='translation'), Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='domains', value='Stanford'), Comparison(comparator=<Comparator.GTE: 'gte'>, attribute='num_datapoints', value=100000.0), Comparison(comparator=<Comparator.GT: 'gt'>, attribute='size_in_mb', value=100), Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='languages', value='sk'), Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='languages', value='pl')]), Operation(operator=<Operator.NOT: 'not'>, arguments=[Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='languages', value='cz')])]), limit=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StructuredQueryOutputParser.from_components(fix_invalid=False).invoke(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('translation datasets',\n",
       " {'expr': '(( task_types == \"translation\" ) and ( domains == \"Stanford\" ) and ( num_datapoints >= 100000.0 ) and ( size_in_mb > 100 ) and (( languages == \"sk\" ) and ( languages == \"pl\" )) and not(( languages == \"cz\" )))'})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MilvusTranslator().visit_structured_query(\n",
    "    StructuredQueryOutputParser.from_components(fix_invalid=True).invoke(output)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main problems to tackle:\n",
    "- Hallucinations\n",
    "- Not adhering to schema, to permitted values of individual fields...\n",
    "    - If model creates a filter that doesnt adhere to the schema of a particular metadata field (lets say: datasets from AIoD platform), in that case we shall add this information to the query instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tailor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
